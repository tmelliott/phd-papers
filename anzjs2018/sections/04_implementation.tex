\section{Real-time implementation}
\label{sec:rt}

The application consists of two components:
the first handles importing static GTFS data and constructing the network,
while the second implements the \rt models and prediction.
We chose \verb+Rcpp+ to develop the program,
which provides access to other R packages for data manipulation 
(notably \verb+RSQLite+ and \verb+dplyr+),
as well as the speed and memory management capabilities of \verb|C++|. 
The program is implemented in the R package
\verb+transitr+, available on Github (\url{https://github.com/tmelliott/transitr}).
In this section, we discuss the features of the \rt component
and assess its performance in \rt,
both with respect to timing and parameter estimation.

The general structure of the \rt component is shown below,
with the bold steps being those discussed in this paper.
\begin{enumerate}
\item Load GTFS data from database
\item Each time new data are recieved \ldots
\begin{enumerate}
    \item Update or create new vehicle objects from the new data
    \item \textbf{Run particle filter on each vehicle to update or initialise state}
    \item \textbf{Update state of any roads for which vehicles 
        have completed travel}
    \item Generate ETAs for vehicles uing combination of particle filter and network state
    \item Write ETAs to extended Google Protobuf binary file for distribution
\end{enumerate}
\end{enumerate}


During the development of the application,
we were primarly concerned with ensuring each component of the program
is as efficient as possible,
allowing ETAs to be generated and distributed fast enough to be faesible in real-time,
with a target of 30~seconds or faster at peak time.
Using C++ provides the memory management control necessary to make the application
viable in real-time.
We also make use of OpenMP for parallisation,
since each vehicle is modelled independently so it is trivial to scale up without
worrying about threadsafety.


The number of particles needed per vehicle 
depends on many factors,
so it is necessary to explore the performance of the application
with varying number of particles.
Application performance is also assessed
for a range of fixed model parameter values,
such as system noise and GPS error.
To enable comparisons, we implemented a simulated \rt environment
in which the same subset of real vehicle data from 8~October, 2018
could be analysed using a range of settings.
These simulations were carried out of a Virtual Machine 
with 8~cores and 32~Gb of memory, 
running Ubuntu~16.04 and using R~3.4.1.


\subsection{Program Timings}
\label{sec:timings}

In each iteration, 
the timing of the various program components is recorded.
Since the number of vehicles traveling at any given time changes throughout the day,
we used the average timings over an off-peak 15~minute window.
Figure~\ref{fig:timings} shows the average timings for 
varying numbers of particles, $N$.


The most time consuming component is ETA writing,
which involves summarising the individual ETAs estimated for each particle.
While not discussed here this involves quantiles which use a sorting algorithm,
which has complexity $O(N \log N)$ 
which explains the slightly quadratic trend in the timings.


The next most intensive step is vehicle updating,
and takes about 5~seconds for 8000 particles.
The ETA prediction step only takes a few seconds,
although this may increase once a more comprehensive model is developed.
On our 8-core virtual machine the entire process is completed within 20~seconds
when 8000~particles are used.
In the next section we explore the effect of changing $N$
to allow finding the optimal number.


\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/04_model_results_timing.pdf}
    \caption{The timings for various parts of the application, and overall. %
        The trend is slightly non-linear due to the complexity of the ETA generation step, %
        which requires sorting of the particle ETAs to obtain quantile estimates.}
    \label{fig:timings}
\end{figure}




\subsection{Model performance}
\label{sec:model_perf}


For each simulation, 
the model was evaluated using several statistics.
These were effective sample size, $N_\text{eff}$ calculated using (\ref{eq:neff});
degeneration rate, the percentage of iterations in which the vehicle was lost
(no plausible particles);
and the variance of segment travel time estimates.


The GPS error parameter values were chosen by examining the distribution
of the distance between observations and the nearest point on the route.
This is shown in Figure~\ref{fig:dist_to_route},
in which we see a peak at about 1m and another at 2.5m,
so we have chosen GPS error values of $\epsilon \in \{1,2,3,5\}$.
System error is the variation of speed per second,
or acceleration rate,
so our chosen values of $\sigma^2\in \{1e^{-4},1e^{-3},1e^{-2},0.05\}$ 
correspond to a variance of 0.09, 0.9, 9, and 45 meters per second over 
30~seconds.


\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/04_model_results_dist.pdf}
    \caption{The distance between the observation and the nearest point on the shape.}
    \label{fig:dist_to_route}
\end{figure}


From Figure~\ref{fig:degen_rate}, we see that $N_\text{eff}$ increases
with GPS error and decreases with system noise.
The degeneration rate decreases with GPS error and increases with $N$,
but is relatively unaffected by system noise.
Large GPS error affects the likelihood,
and gives more weight to particles farther from the observation
than does a smaller GPS error.
Conversesly, increasing system noise spreads out the particle cloud,
so fewer particles will be near the vehicle.
Thus, these results are not surprising, 
but show that the model is working as expected.


\begin{figure}[tb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/04_model_results_degen.pdf}
    \caption{The effective sample size and degeneration rate for a range of parameter 
        values. The columns are of increasing number of particles,
        and the rows are for increasing (downwards) GPS error.}
    \label{fig:degen_rate}
\end{figure}


The last measure of performance is the variance of segment travel times.
This is calculated by \_\_\_.
Figure~\ref{fig:travel_times} shows that variance increases with GPS error,
and decreases with $N$,
with little effect made by system noise.
There is therefore a tradeoff between particle filter performance
($N_\text{eff}$ and degeneration rate) and parameter estimation,
although the true test will be calculating the prediction error
of ETAs once the prediction model has been implemented.


\begin{figure}[tb]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/04_model_results_times.pdf}
    \caption{The within-segment posterior travel time uncertainty (standard error), subset by number of particles.}
    \label{fig:travel_times}
\end{figure}


